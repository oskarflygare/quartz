---
created: 2022-09-07
updated: 2023-09-01
tags:
  - book
author: Cecilia Kang, Sheera Frenkel
---
# Key takeaways
* Mark Zuckerberg has always been a developer first. More interested in adding new features rather than the "upkeep" of content moderation or impacts in politics
* Facebook was very passive during the 2016 election, everyone just assumed that Hillary Clinton would win but instead Donald Trump was able to generate a lot of engagement through his outrageous content.
* Russia deliberately hacked Hillary Clinton's email and other members of the democratic party.
* They mentioned the [[Pied Piper]] story as well as [[Canary in a coal mine]] metaphors

---

## Highlights
- “We assess,” the summary read, “with moderate to high confidence that Russian state-sponsored actors are using Facebook in an attempt to influence the broader political discourse via the deliberate spread of questionable news articles, the spread of information from data breaches intended to discredit, and actively engaging with journalists to spread said stolen information.” ([Location 1647](https://readwise.io/to_kindle?action=open&asin=B09461YYFV&location=1647))
- But Schissler and others realized the stickers were having an unintended consequence: Facebook’s algorithms counted them as one more way people were enjoying a post. Instead of diminishing the number of people who saw a piece of hate speech, the stickers had the opposite effect of making the posts more popular. ([Location 2505](https://readwise.io/to_kindle?action=open&asin=B09461YYFV&location=2505))
- Facebook was designed to throw gas on the fire of any speech that invoked an emotion, even if it was hateful speech—its algorithms favored sensationalism. Whether a user clicked on a link because they were curious, horrified, or engaged was immaterial; the system saw that the post was being widely read, and it promoted it more widely across users’ Facebook pages. The situation in Myanmar was a deadly experiment in what could happen when the internet landed in a country where a social network became the primary, and most widely trusted, source of news. ([Location 2519](https://readwise.io/to_kindle?action=open&asin=B09461YYFV&location=2519))
- The harms were baked into the design. As Dipayan Ghosh, a former Facebook privacy expert, noted, “We have set ethical red lines in society, but when you have a machine that prioritizes engagement, it will always be incentivized to cross those lines.” ([Location 2563](https://readwise.io/to_kindle?action=open&asin=B09461YYFV&location=2563))
- First Amendment, which was designed to protect speech from government censorship. The very people Zuckerberg aimed to protect, political figures, could wield the most harm: “The company has refused to fully recognize the threat of voter suppression and intimidation here at home, especially from users that the company refers to as ‘authentic voices’—politicians and candidates for public office,” Ifill asserted. ([Location 3513](https://readwise.io/to_kindle?action=open&asin=B09461YYFV&location=3513))
- The technology created echo chambers of like-minded individuals sharing the same stories. ([Location 3518](https://readwise.io/to_kindle?action=open&asin=B09461YYFV&location=3518))
- The algorithm that serves as Facebook’s beating heart is too powerful and too lucrative. And the platform is built upon a fundamental, possibly irreconcilable dichotomy: its purported mission to advance society by connecting people while also profiting off them. It is Facebook’s dilemma and its ugly truth. ([Location 4128](https://readwise.io/to_kindle?action=open&asin=B09461YYFV&location=4128))
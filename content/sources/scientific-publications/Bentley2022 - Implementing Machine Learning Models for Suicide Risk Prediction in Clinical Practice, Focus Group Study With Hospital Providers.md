---
created: 2023-02-07
updated: 2023-08-31
---
# Bentley2022 - Implementing Machine Learning Models for Suicide Risk Prediction in Clinical Practice, Focus Group Study With Hospital Providers

* Type: #article
* Date read: 2023-02-07
* Subject: [[Suicide]] [[machine learning]]
* Bibtex: @bentley2022
* Bibliography: Bentley, K. H., Zuromski, K. L., Fortgang, R. G., Madsen, E. M., Kessler, D., Lee, H., Nock, M. K., Reis, B. Y., Castro, V. M., & Smoller, J. W. (2022). Implementing Machine Learning Models for Suicide Risk Prediction in Clinical Practice: Focus Group Study With Hospital Providers. _JMIR Formative Research_, _6_(3), e30946. [https://doi.org/10.2196/30946](https://doi.org/10.2196/30946)
---
# Example citation


# Key takeaways
* 10 focus groups, 40 hospital providers in various disciplines of medicine. At MGH in Boston. 
* Qualitative analysis of audio recordings
	* (1) Current suicide risk assessment practices
	* (2) Current suicide risk intervention practices
	* (3) Attitudes about current assessment and interventions
	* (4) General reactions and attitudes toward using ML for suicide risk prediction in clinical practice
	* (5) Factors to consider when developing or implementing such models
	* (6) Barriers and concerns to using such systems
	* (7) Recommendations about system content or format
	* (8) Recommendations about placement of systems within the electronic health record
* 53% of the participants felt that they received *too many* alerts per week from the electronic health record. Is this true in Sweden? My experience is that we don't really have alerts in this way. *Alert fatigue*
* Future direction: include ideas from patients as well?

---

> Notably, developing a safety plan or other brief, suicide-focused interventions with empirical support [24] was only mentioned in 20% (2/10) of the groups.


> The single most common barrier to the potential use of automated suicide riskâ€“prediction models in routine care was the implication for liability. For example, many were concerned about being held legally responsible if they decided not to hospitalize a patient who was categorized as high risk and then went on to attempt or die by suicide.

Is this an American-specific concern? I would be surprised if this was the number one concern in Sweden, for example.

![[Screenshot 2023-02-07 at 13.14.30.png]]